# AI QA Agent - Sanity Testing Guide

## Overview
This guide provides comprehensive sanity tests to verify that the AI QA Agent system is properly deployed and all components are functioning correctly. These tests should be run after both local and cloud deployments.

## Prerequisites

### Testing Environment Setup
```bash
# Set environment variables based on your deployment
# For Local Deployment:
export BASE_URL="http://localhost:8000"
export ENVIRONMENT="local"

# For AWS Cloud Deployment:
# export BASE_URL="http://your-alb-url"
# export ENVIRONMENT="aws"

# Verify environment
echo "Testing environment: $ENVIRONMENT"
echo "Base URL: $BASE_URL"
```

### Required Tools
```bash
# Install testing tools if not already present
pip install requests pytest httpx websockets aiohttp

# For manual testing
sudo apt-get install curl jq  # Linux
brew install curl jq          # macOS
```

## Test Suite 1: Infrastructure Health Checks

### 1.1 Basic System Health
```bash
echo "üîç Test 1.1: Basic System Health"

# Test basic health endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/health/)
http_code="${response: -3}"
response_body="${response%???}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Basic health check: PASS"
    echo "   Response: $response_body"
else
    echo "‚ùå Basic health check: FAIL (HTTP $http_code)"
    echo "   Response: $response_body"
fi

# Test detailed health endpoint
echo ""
echo "Testing detailed health endpoint..."
curl -s $BASE_URL/health/detailed | jq '.'
```

### 1.2 Database Connectivity
```bash
echo ""
echo "üîç Test 1.2: Database Connectivity"

# Test database health through API
response=$(curl -s $BASE_URL/health/detailed)
db_status=$(echo $response | jq -r '.database.status // "unknown"')

if [ "$db_status" = "healthy" ]; then
    echo "‚úÖ Database connectivity: PASS"
else
    echo "‚ùå Database connectivity: FAIL"
    echo "   Database status: $db_status"
fi

# Test database tables exist
python3 -c "
import sys
sys.path.append('.')
try:
    from src.core.database import engine
    from sqlalchemy import text
    with engine.connect() as conn:
        result = conn.execute(text('SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = \\'public\\';'))
        table_count = result.scalar()
        print(f'‚úÖ Database tables: {table_count} tables found')
        if table_count < 5:
            print('‚ö†Ô∏è  Warning: Expected more tables, check database initialization')
except Exception as e:
    print(f'‚ùå Database connection failed: {e}')
"
```

### 1.3 Redis Connectivity
```bash
echo ""
echo "üîç Test 1.3: Redis Connectivity"

# Test Redis health through API
redis_status=$(curl -s $BASE_URL/health/detailed | jq -r '.redis.status // "unknown"')

if [ "$redis_status" = "healthy" ]; then
    echo "‚úÖ Redis connectivity: PASS"
else
    echo "‚ùå Redis connectivity: FAIL"
    echo "   Redis status: $redis_status"
fi

# Test Redis operations
python3 -c "
import sys
sys.path.append('.')
try:
    import redis
    from src.core.config import get_settings
    settings = get_settings()
    r = redis.Redis.from_url(settings.redis_url)
    r.ping()
    r.set('sanity_test', 'success')
    result = r.get('sanity_test')
    r.delete('sanity_test')
    print('‚úÖ Redis operations: PASS')
except Exception as e:
    print(f'‚ùå Redis operations: FAIL - {e}')
"
```

## Test Suite 2: Core API Functionality

### 2.1 Analysis API Endpoints
```bash
echo ""
echo "üîç Test 2.1: Analysis API Endpoints"

# Test analysis status endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/analysis/status)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Analysis status endpoint: PASS"
else
    echo "‚ùå Analysis status endpoint: FAIL (HTTP $http_code)"
fi

# Test analysis test endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/analysis/test)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Analysis test endpoint: PASS"
else
    echo "‚ùå Analysis test endpoint: FAIL (HTTP $http_code)"
fi

# Test file analysis with sample code
echo ""
echo "Testing file analysis with sample Python code..."
python3 -c "
import requests
import json

sample_code = '''
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

def main():
    result = fibonacci(10)
    print(f'Fibonacci(10) = {result}')

if __name__ == '__main__':
    main()
'''

try:
    response = requests.post(
        '$BASE_URL/api/v1/analysis/analyze/content',
        json={'content': sample_code, 'language': 'python'},
        timeout=30
    )
    
    if response.status_code == 200:
        data = response.json()
        print('‚úÖ Code analysis: PASS')
        print(f'   Functions found: {len(data.get(\"functions\", []))}')
        print(f'   Complexity score: {data.get(\"complexity_metrics\", {}).get(\"average_complexity\", \"N/A\")}')
    else:
        print(f'‚ùå Code analysis: FAIL (HTTP {response.status_code})')
        print(f'   Response: {response.text[:200]}')
        
except Exception as e:
    print(f'‚ùå Code analysis: FAIL - {e}')
"
```

### 2.2 Agent System Endpoints
```bash
echo ""
echo "üîç Test 2.2: Agent System Endpoints"

# Test agent status
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/agent/status)
http_code="${response: -3}"
response_body="${response%???}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Agent status endpoint: PASS"
    agent_count=$(echo $response_body | jq -r '.available_agents // 0')
    echo "   Available agents: $agent_count"
else
    echo "‚ùå Agent status endpoint: FAIL (HTTP $http_code)"
fi

# Test agent specialists endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/agent/specialists)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Agent specialists endpoint: PASS"
else
    echo "‚ùå Agent specialists endpoint: FAIL (HTTP $http_code)"
fi

# Test agent conversation with simple request
echo ""
echo "Testing agent conversation..."
python3 -c "
import requests
import json

try:
    response = requests.post(
        '$BASE_URL/api/v1/agent/conversation',
        json={
            'message': 'Hello, can you help me understand what you can do?',
            'session_id': 'sanity_test_001'
        },
        timeout=30
    )
    
    if response.status_code == 200:
        data = response.json()
        print('‚úÖ Agent conversation: PASS')
        print(f'   Response length: {len(data.get(\"response\", \"\"))} characters')
        print(f'   Agent used: {data.get(\"agent_name\", \"unknown\")}')
    else:
        print(f'‚ùå Agent conversation: FAIL (HTTP {response.status_code})')
        print(f'   Response: {response.text[:200]}')
        
except Exception as e:
    print(f'‚ùå Agent conversation: FAIL - {e}')
"
```

### 2.3 Chat API Endpoints
```bash
echo ""
echo "üîç Test 2.3: Chat API Endpoints"

# Test chat sessions endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/chat/sessions)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Chat sessions endpoint: PASS"
else
    echo "‚ùå Chat sessions endpoint: FAIL (HTTP $http_code)"
fi

# Test chat message endpoint
echo ""
echo "Testing chat message..."
python3 -c "
import requests

try:
    # Create a chat session
    response = requests.post(
        '$BASE_URL/api/v1/chat/sessions',
        json={'metadata': {'test': 'sanity_check'}},
        timeout=15
    )
    
    if response.status_code == 200:
        session_data = response.json()
        session_id = session_data['session_id']
        print(f'‚úÖ Chat session creation: PASS (ID: {session_id})')
        
        # Send a test message
        response = requests.post(
            '$BASE_URL/api/v1/chat/message',
            json={
                'message': 'What is the purpose of unit testing?',
                'session_id': session_id
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            print('‚úÖ Chat message: PASS')
            print(f'   Response length: {len(data.get(\"response\", \"\"))} characters')
        else:
            print(f'‚ùå Chat message: FAIL (HTTP {response.status_code})')
    else:
        print(f'‚ùå Chat session creation: FAIL (HTTP {response.status_code})')
        
except Exception as e:
    print(f'‚ùå Chat API test: FAIL - {e}')
"
```

## Test Suite 3: Learning and Analytics

### 3.1 Learning Analytics Endpoints
```bash
echo ""
echo "üîç Test 3.1: Learning Analytics Endpoints"

# Test learning analytics endpoint
response=$(curl -s -w "%{http_code}" "$BASE_URL/api/v1/learning/analytics/agent-intelligence")
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Learning analytics endpoint: PASS"
else
    echo "‚ùå Learning analytics endpoint: FAIL (HTTP $http_code)"
fi

# Test improvement opportunities endpoint
response=$(curl -s -w "%{http_code}" "$BASE_URL/api/v1/learning/analytics/improvement-opportunities")
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Improvement opportunities endpoint: PASS"
else
    echo "‚ùå Improvement opportunities endpoint: FAIL (HTTP $http_code)"
fi
```

### 3.2 Learning System Functionality
```bash
echo ""
echo "üîç Test 3.2: Learning System Functionality"

python3 -c "
import sys
sys.path.append('.')
try:
    import asyncio
    from src.agent.learning.learning_engine import get_learning_engine
    
    async def test_learning():
        try:
            engine = await get_learning_engine()
            print('‚úÖ Learning engine initialization: PASS')
            return True
        except Exception as e:
            print(f'‚ùå Learning engine initialization: FAIL - {e}')
            return False
    
    success = asyncio.run(test_learning())
    
except Exception as e:
    print(f'‚ùå Learning system test: FAIL - {e}')
"
```

## Test Suite 4: Web Interface Validation

### 4.1 Web Routes Accessibility
```bash
echo ""
echo "üîç Test 4.1: Web Routes Accessibility"

# Test main dashboard
response=$(curl -s -w "%{http_code}" $BASE_URL/)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Main dashboard route: PASS"
else
    echo "‚ùå Main dashboard route: FAIL (HTTP $http_code)"
fi

# Test agent chat interface
response=$(curl -s -w "%{http_code}" $BASE_URL/agent-chat)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Agent chat interface: PASS"
else
    echo "‚ùå Agent chat interface: FAIL (HTTP $http_code)"
fi

# Test analytics dashboard
response=$(curl -s -w "%{http_code}" $BASE_URL/analytics)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Analytics dashboard: PASS"
else
    echo "‚ùå Analytics dashboard: FAIL (HTTP $http_code)"
fi

# Test demos page
response=$(curl -s -w "%{http_code}" $BASE_URL/demos)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Demos page: PASS"
else
    echo "‚ùå Demos page: FAIL (HTTP $http_code)"
fi

# Test API documentation
response=$(curl -s -w "%{http_code}" $BASE_URL/docs)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ API documentation: PASS"
else
    echo "‚ùå API documentation: FAIL (HTTP $http_code)"
fi
```

### 4.2 Static Assets Loading
```bash
echo ""
echo "üîç Test 4.2: Static Assets Loading"

# Check if CSS is loading (look for CSS content)
css_response=$(curl -s $BASE_URL/static/css/agent_interface.css 2>/dev/null || echo "not_found")
if [[ "$css_response" == *"not_found"* ]] || [ -z "$css_response" ]; then
    echo "‚ö†Ô∏è  CSS assets: Not accessible (may be embedded)"
else
    echo "‚úÖ CSS assets: PASS"
fi

# Check if JavaScript is loading
js_response=$(curl -s $BASE_URL/static/js/agent_conversation.js 2>/dev/null || echo "not_found")
if [[ "$js_response" == *"not_found"* ]] || [ -z "$js_response" ]; then
    echo "‚ö†Ô∏è  JavaScript assets: Not accessible (may be embedded)"
else
    echo "‚úÖ JavaScript assets: PASS"
fi
```

## Test Suite 5: Intelligent Operations

### 5.1 Cost Optimization System
```bash
echo ""
echo "üîç Test 5.1: Cost Optimization System"

python3 -c "
import sys
sys.path.append('.')
try:
    import asyncio
    from src.operations.optimization.cost_optimization import get_cost_optimizer
    
    async def test_cost_optimization():
        try:
            optimizer = await get_cost_optimizer()
            print('‚úÖ Cost optimizer initialization: PASS')
            
            # Test AI provider optimization
            ai_opt = await optimizer.optimize_ai_provider_usage()
            print(f'‚úÖ AI provider optimization: PASS')
            print(f'   Potential savings: {ai_opt.savings_percentage:.1f}%')
            
            return True
        except Exception as e:
            print(f'‚ùå Cost optimization test: FAIL - {e}')
            return False
    
    asyncio.run(test_cost_optimization())
    
except Exception as e:
    print(f'‚ùå Cost optimization import: FAIL - {e}')
"
```

### 5.2 Intelligent Alerting System
```bash
echo ""
echo "üîç Test 5.2: Intelligent Alerting System"

python3 -c "
import sys
sys.path.append('.')
try:
    import asyncio
    from src.operations.alerting.intelligent_alerting import get_intelligent_alerting, AlertSeverity
    
    async def test_alerting():
        try:
            alerting = await get_intelligent_alerting()
            print('‚úÖ Intelligent alerting initialization: PASS')
            
            # Test alert generation
            alert = await alerting.generate_intelligent_alert(
                title='Sanity Test Alert',
                description='Test alert for system validation',
                source_system='sanity_test',
                severity=AlertSeverity.INFO,
                metrics={'test_metric': 1.0}
            )
            print('‚úÖ Alert generation: PASS')
            print(f'   Alert ID: {alert.alert_id}')
            print(f'   Noise score: {alert.noise_score:.2f}')
            
            return True
        except Exception as e:
            print(f'‚ùå Intelligent alerting test: FAIL - {e}')
            return False
    
    asyncio.run(test_alerting())
    
except Exception as e:
    print(f'‚ùå Intelligent alerting import: FAIL - {e}')
"
```

### 5.3 Performance Excellence Monitoring
```bash
echo ""
echo "üîç Test 5.3: Performance Excellence Monitoring"

python3 -c "
import sys
sys.path.append('.')
try:
    import asyncio
    from src.operations.excellence.performance_excellence import get_excellence_monitor
    
    async def test_excellence():
        try:
            monitor = await get_excellence_monitor()
            print('‚úÖ Excellence monitor initialization: PASS')
            
            # Test metrics tracking
            metrics = await monitor.track_excellence_metrics()
            print('‚úÖ Excellence metrics tracking: PASS')
            print(f'   Uptime: {metrics.uptime_percentage:.2f}%')
            print(f'   Response time P95: {metrics.response_time_p95:.0f}ms')
            
            return True
        except Exception as e:
            print(f'‚ùå Performance excellence test: FAIL - {e}')
            return False
    
    asyncio.run(test_excellence())
    
except Exception as e:
    print(f'‚ùå Performance excellence import: FAIL - {e}')
"
```

## Test Suite 6: Monitoring and Observability

### 6.1 Metrics Endpoints
```bash
echo ""
echo "üîç Test 6.1: Metrics Endpoints"

# Test Prometheus metrics endpoint
response=$(curl -s -w "%{http_code}" $BASE_URL/metrics)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Prometheus metrics endpoint: PASS"
    metrics_count=$(echo "${response%???}" | grep -c "^# HELP" || echo "0")
    echo "   Metrics exposed: $metrics_count"
else
    echo "‚ùå Prometheus metrics endpoint: FAIL (HTTP $http_code)"
fi

# Test monitoring health
response=$(curl -s -w "%{http_code}" $BASE_URL/health/monitoring)
http_code="${response: -3}"

if [ "$http_code" -eq 200 ]; then
    echo "‚úÖ Monitoring health endpoint: PASS"
else
    echo "‚ùå Monitoring health endpoint: FAIL (HTTP $http_code)"
fi
```

### 6.2 External Monitoring Services (AWS/Local)
```bash
echo ""
echo "üîç Test 6.2: External Monitoring Services"

if [ "$ENVIRONMENT" = "local" ]; then
    # Test local Prometheus
    prometheus_response=$(curl -s -w "%{http_code}" http://localhost:9090/api/v1/query?query=up 2>/dev/null || echo "000not_reachable")
    prometheus_code="${prometheus_response: -3}"
    
    if [ "$prometheus_code" -eq 200 ]; then
        echo "‚úÖ Local Prometheus: PASS"
    else
        echo "‚ö†Ô∏è  Local Prometheus: Not accessible (may not be running)"
    fi
    
    # Test local Grafana
    grafana_response=$(curl -s -w "%{http_code}" http://localhost:3000/api/health 2>/dev/null || echo "000not_reachable")
    grafana_code="${grafana_response: -3}"
    
    if [ "$grafana_code" -eq 200 ]; then
        echo "‚úÖ Local Grafana: PASS"
    else
        echo "‚ö†Ô∏è  Local Grafana: Not accessible (may not be running)"
    fi
    
elif [ "$ENVIRONMENT" = "aws" ]; then
    echo "‚ö†Ô∏è  AWS CloudWatch monitoring: Manual verification required"
    echo "   Check CloudWatch console for EKS cluster metrics"
    echo "   Check Application Load Balancer target health"
fi
```

## Test Suite 7: Performance Baseline Validation

### 7.1 Response Time Testing
```bash
echo ""
echo "üîç Test 7.1: Response Time Testing"

python3 -c "
import time
import requests
import statistics

def test_response_times(url, endpoint, count=5):
    times = []
    for i in range(count):
        start = time.time()
        try:
            response = requests.get(f'{url}{endpoint}', timeout=10)
            end = time.time()
            if response.status_code == 200:
                times.append((end - start) * 1000)  # Convert to milliseconds
        except Exception:
            pass
        time.sleep(0.5)  # Small delay between requests
    
    if times:
        avg_time = statistics.mean(times)
        max_time = max(times)
        return avg_time, max_time, len(times)
    return None, None, 0

# Test key endpoints
endpoints = [
    '/health/',
    '/api/v1/analysis/status',
    '/api/v1/agent/status',
    '/'
]

print('Response Time Analysis:')
print('Endpoint                    Avg (ms)  Max (ms)  Success Rate')
print('-' * 65)

for endpoint in endpoints:
    avg, max_time, success_count = test_response_times('$BASE_URL', endpoint)
    if avg is not None:
        success_rate = (success_count / 5) * 100
        status = '‚úÖ' if avg < 1000 and success_rate >= 80 else '‚ö†Ô∏è ' if avg < 2000 else '‚ùå'
        print(f'{status} {endpoint:<25} {avg:>7.0f}  {max_time:>7.0f}  {success_rate:>6.0f}%')
    else:
        print(f'‚ùå {endpoint:<25}    FAIL     FAIL      0%')
"
```

### 7.2 Concurrent Request Testing
```bash
echo ""
echo "üîç Test 7.2: Concurrent Request Testing"

python3 -c "
import asyncio
import aiohttp
import time

async def make_request(session, url):
    try:
        async with session.get(url, timeout=10) as response:
            return response.status == 200
    except:
        return False

async def test_concurrent_requests(url, concurrent=10):
    start_time = time.time()
    
    async with aiohttp.ClientSession() as session:
        tasks = [make_request(session, f'{url}/health/') for _ in range(concurrent)]
        results = await asyncio.gather(*tasks)
    
    end_time = time.time()
    duration = end_time - start_time
    success_count = sum(results)
    success_rate = (success_count / concurrent) * 100
    
    return duration, success_rate, success_count

# Test with 10 concurrent requests
duration, success_rate, success_count = asyncio.run(test_concurrent_requests('$BASE_URL'))

if success_rate >= 90:
    print(f'‚úÖ Concurrent request test: PASS')
else:
    print(f'‚ö†Ô∏è  Concurrent request test: PARTIAL')

print(f'   {success_count}/10 requests succeeded ({success_rate:.0f}%)')
print(f'   Total duration: {duration:.2f} seconds')
print(f'   Average per request: {duration/10*1000:.0f}ms')
"
```

## Test Suite 8: Security Validation

### 8.1 Basic Security Headers
```bash
echo ""
echo "üîç Test 8.1: Basic Security Headers"

python3 -c "
import requests

try:
    response = requests.get('$BASE_URL/health/', timeout=10)
    headers = response.headers
    
    security_headers = {
        'X-Content-Type-Options': 'nosniff',
        'X-Frame-Options': None,  # Any value is good
        'X-XSS-Protection': None,  # Any value is good
        'Strict-Transport-Security': None  # Expected in HTTPS
    }
    
    print('Security Headers Check:')
    for header, expected in security_headers.items():
        if header in headers:
            print(f'‚úÖ {header}: Present ({headers[header]})')
        else:
            if header == 'Strict-Transport-Security' and '$BASE_URL'.startswith('http://'):
                print(f'‚ö†Ô∏è  {header}: Not present (expected for HTTP)')
            else:
                print(f'‚ö†Ô∏è  {header}: Missing')
    
except Exception as e:
    print(f'‚ùå Security headers test: FAIL - {e}')
"
```

### 8.2 API Authentication (if enabled)
```bash
echo ""
echo "üîç Test 8.2: API Authentication"

# Test if API requires authentication (should return 401/403 for protected endpoints)
response=$(curl -s -w "%{http_code}" $BASE_URL/api/v1/admin/users 2>/dev/null || echo "404")
http_code="${response: -3}"

if [ "$http_code" -eq 404 ]; then
    echo "‚ö†Ô∏è  Admin endpoints: Not implemented (expected)"
elif [ "$http_code" -eq 401 ] || [ "$http_code" -eq 403 ]; then
    echo "‚úÖ API authentication: Properly protected"
else
    echo "‚ö†Ô∏è  API authentication: Admin endpoints accessible without auth"
fi
```

## Test Suite 9: Integration Testing

### 9.1 End-to-End Agent Workflow
```bash
echo ""
echo "üîç Test 9.1: End-to-End Agent Workflow"

python3 -c "
import requests
import time

def test_agent_workflow():
    try:
        # 1. Create a chat session
        session_response = requests.post(
            '$BASE_URL/api/v1/chat/sessions',
            json={'metadata': {'test': 'e2e_workflow'}},
            timeout=15
        )
        
        if session_response.status_code != 200:
            print(f'‚ùå Session creation failed: {session_response.status_code}')
            return False
            
        session_id = session_response.json()['session_id']
        print(f'‚úÖ Step 1 - Session created: {session_id}')
        
        # 2. Send analysis request
        analysis_request = {
            'message': 'Please analyze this Python function for testing opportunities: def add(a, b): return a + b',
            'session_id': session_id
        }
        
        chat_response = requests.post(
            '$BASE_URL/api/v1/chat/message',
            json=analysis_request,
            timeout=30
        )
        
        if chat_response.status_code != 200:
            print(f'‚ùå Chat analysis failed: {chat_response.status_code}')
            return False
            
        chat_data = chat_response.json()
        print('‚úÖ Step 2 - Analysis completed')
        print(f'   Response length: {len(chat_data.get(\"response\", \"\"))}')
        
        # 3. Test agent conversation
        agent_request = {
            'message': 'Can you help me write unit tests for the add function?',
            'session_id': session_id
        }
        
        agent_response = requests.post(
            '$BASE_URL/api/v1/agent/conversation',
            json=agent_request,
            timeout=30
        )
        
        if agent_response.status_code != 200:
            print(f'‚ùå Agent conversation failed: {agent_response.status_code}')
            return False
            
        agent_data = agent_response.json()
        print('‚úÖ Step 3 - Agent conversation completed')
        print(f'   Agent: {agent_data.get(\"agent_name\", \"unknown\")}')
        
        # 4. Verify session history
        history_response = requests.get(
            f'$BASE_URL/api/v1/chat/sessions/{session_id}',
            timeout=15
        )
        
        if history_response.status_code != 200:
            print(f'‚ùå Session history failed: {history_response.status_code}')
            return False
            
        history_data = history_response.json()
        message_count = len(history_data.get('messages', []))
        print(f'‚úÖ Step 4 - Session history verified: {message_count} messages')
        
        print('‚úÖ End-to-end agent workflow: COMPLETE')
        return True
        
    except Exception as e:
        print(f'‚ùå End-to-end workflow failed: {e}')
        return False

test_agent_workflow()
"
```

### 9.2 Analysis and Generation Pipeline
```bash
echo ""
echo "üîç Test 9.2: Analysis and Generation Pipeline"

python3 -c "
import requests
import time

def test_analysis_pipeline():
    try:
        # Test code analysis
        sample_code = '''
class Calculator:
    def add(self, a, b):
        return a + b
    
    def multiply(self, a, b):
        result = 0
        for i in range(b):
            result = self.add(result, a)
        return result
        '''
        
        analysis_response = requests.post(
            '$BASE_URL/api/v1/analysis/analyze/content',
            json={'content': sample_code, 'language': 'python'},
            timeout=30
        )
        
        if analysis_response.status_code != 200:
            print(f'‚ùå Code analysis failed: {analysis_response.status_code}')
            return False
            
        analysis_data = analysis_response.json()
        print('‚úÖ Code analysis completed')
        print(f'   Functions found: {len(analysis_data.get(\"functions\", []))}')
        print(f'   Classes found: {len(analysis_data.get(\"classes\", []))}')
        
        # Test agent-based test generation
        generation_request = {
            'message': f'Generate comprehensive unit tests for this code: {sample_code}',
            'session_id': 'pipeline_test'
        }
        
        agent_response = requests.post(
            '$BASE_URL/api/v1/agent/conversation',
            json=generation_request,
            timeout=45
        )
        
        if agent_response.status_code != 200:
            print(f'‚ùå Test generation failed: {agent_response.status_code}')
            return False
            
        agent_data = agent_response.json()
        response_text = agent_data.get('response', '')
        
        if 'test' in response_text.lower() and len(response_text) > 100:
            print('‚úÖ Test generation completed')
            print(f'   Generated response length: {len(response_text)} characters')
        else:
            print('‚ö†Ô∏è  Test generation: Response may be incomplete')
            
        print('‚úÖ Analysis and generation pipeline: COMPLETE')
        return True
        
    except Exception as e:
        print(f'‚ùå Analysis pipeline failed: {e}')
        return False

test_analysis_pipeline()
"
```

## Summary Report Generation

### Generate Sanity Test Report
```bash
echo ""
echo "üîç Generating Sanity Test Summary Report"

# Create a summary report
cat > sanity_test_report.md << EOF
# AI QA Agent - Sanity Test Report

**Test Date**: $(date)
**Environment**: $ENVIRONMENT
**Base URL**: $BASE_URL

## Test Results Summary

### Infrastructure Health
- [x] Basic system health
- [x] Database connectivity  
- [x] Redis connectivity

### Core API Functionality
- [x] Analysis API endpoints
- [x] Agent system endpoints
- [x] Chat API endpoints

### Learning and Analytics
- [x] Learning analytics endpoints
- [x] Learning system functionality

### Web Interface
- [x] Web routes accessibility
- [x] Static assets loading

### Intelligent Operations
- [x] Cost optimization system
- [x] Intelligent alerting system
- [x] Performance excellence monitoring

### Monitoring and Observability
- [x] Metrics endpoints
- [x] External monitoring services

### Performance Validation
- [x] Response time testing
- [x] Concurrent request testing

### Security Validation
- [x] Basic security headers
- [x] API authentication

### Integration Testing
- [x] End-to-end agent workflow
- [x] Analysis and generation pipeline

## Next Steps
1. Run E2E functional tests for complete workflow validation
2. Performance load testing for production readiness
3. Security penetration testing
4. User acceptance testing

**Overall Status**: ‚úÖ SYSTEM OPERATIONAL
EOF

echo "‚úÖ Sanity test report generated: sanity_test_report.md"
```

## Troubleshooting Common Issues

### Issue 1: Health Check Failures
```bash
# Debug health check failures
echo "Debugging health check issues..."

# Check application logs
if [ "$ENVIRONMENT" = "local" ]; then
    echo "Check local logs:"
    echo "tail -f logs/app.log"
elif [ "$ENVIRONMENT" = "aws" ]; then
    echo "Check Kubernetes logs:"
    echo "kubectl logs -f deployment/ai-qa-agent-main -n ai-qa-agent"
fi

# Check database connection
python3 -c "
from src.core.database import engine
try:
    with engine.connect() as conn:
        conn.execute(text('SELECT 1'))
    print('Database connection: OK')
except Exception as e:
    print(f'Database connection: FAIL - {e}')
"
```

### Issue 2: API Timeouts
```bash
# Debug API timeout issues
echo "Debugging API timeouts..."

# Check if AI providers are accessible
python3 -c "
import openai
import anthropic
from src.core.config import get_settings

settings = get_settings()
try:
    if settings.openai_api_key:
        # Test OpenAI connection
        client = openai.OpenAI(api_key=settings.openai_api_key)
        # Don't make actual API call in sanity test
        print('OpenAI client: Configured')
    else:
        print('OpenAI client: No API key')
        
    if settings.anthropic_api_key:
        # Test Anthropic connection
        client = anthropic.Anthropic(api_key=settings.anthropic_api_key)
        print('Anthropic client: Configured')
    else:
        print('Anthropic client: No API key')
        
except Exception as e:
    print(f'AI provider configuration: {e}')
"
```

### Issue 3: Agent System Failures
```bash
# Debug agent system issues
echo "Debugging agent system..."

python3 -c "
import asyncio
import sys
sys.path.append('.')

async def debug_agent_system():
    try:
        from src.agent.orchestrator import get_agent_orchestrator
        orchestrator = await get_agent_orchestrator()
        print('Agent orchestrator: OK')
        
        from src.agent.specialists.test_architect import TestArchitect
        architect = TestArchitect()
        await architect.initialize()
        print('Test architect: OK')
        
    except Exception as e:
        print(f'Agent system debug: {e}')

asyncio.run(debug_agent_system())
"
```

## Validation Checklist

- [ ] ‚úÖ All health endpoints return 200 status
- [ ] ‚úÖ Database connectivity confirmed
- [ ] ‚úÖ Redis connectivity confirmed  
- [ ] ‚úÖ Core API endpoints functional
- [ ] ‚úÖ Agent system operational
- [ ] ‚úÖ Chat system working
- [ ] ‚úÖ Learning analytics accessible
- [ ] ‚úÖ Web interface loading
- [ ] ‚úÖ Intelligent operations initialized
- [ ] ‚úÖ Monitoring endpoints active
- [ ] ‚úÖ Response times within acceptable limits
- [ ] ‚úÖ Concurrent requests handled properly
- [ ] ‚úÖ Basic security measures in place
- [ ] ‚úÖ End-to-end workflows functional

---

**‚úÖ Sanity testing complete! If all tests pass, your AI QA Agent system is ready for functional testing and production use.**